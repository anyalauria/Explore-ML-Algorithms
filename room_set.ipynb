{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algorithms on Room Occupancy Dataset\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data was in 3 different csv files\n",
    "df1 = pd.read_csv('datasets/room1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('datasets/room2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('datasets/room3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating 3 dataframes together \n",
    "data = df1.append(df2, ignore_index=True).append(df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.query('Occupancy < 1').sample(frac=.65876152832).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the label \n",
    "room_label = data['Occupancy']\n",
    "\n",
    "#removing label from dataframe\n",
    "data.drop(['Occupancy'], axis=1, inplace=True)\n",
    "\n",
    "#dropping columns with missing rows \n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio\n",
       "0  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793\n",
       "1  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783\n",
       "2  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779\n",
       "3  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772\n",
       "4  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].str.replace('\\D', '').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing data\n",
    "continuous_cols = ['date','Temperature','Humidity','Light','CO2','HumidityRatio']\n",
    "features = data[continuous_cols]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "data[continuous_cols] = scaler.transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = room_label\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 5 sets of training and test data \n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y, train_size=5000)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, Y, train_size=5000)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, Y, train_size=5000)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X, Y, train_size=5000)\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X, Y, train_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating arrays of training and test sets \n",
    "train_X_sets = [X1_train,X2_train,X3_train,X4_train,X5_train]\n",
    "test_X_sets = [X1_test,X2_test,X3_test,X4_test,X5_test]\n",
    "\n",
    "#creating arrays of training and test sets \n",
    "train_y_sets = [y1_train,y2_train,y3_train,y4_train,y5_train]\n",
    "test_y_sets = [y1_test,y2_test,y3_test,y4_test,y5_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline in order to grid search \n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "# note lbfgs can't do l1, and if you pass penalty='none' it expects no C value\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-8, 4, 11)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-8, 4, 11)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}\n",
    "                ]\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "logreg_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    logreg_models.append(clf.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "logreg_train_roc_pred = []\n",
    "logreg_test_roc_pred = []\n",
    "\n",
    "logreg_train_acc_pred = []\n",
    "logreg_test_acc_pred = []\n",
    "\n",
    "logreg_train_f1_pred = []\n",
    "logreg_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe.set_params(**proc)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    logreg_train_roc_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_roc_pred.append(pipe.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe.set_params(**pacc)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    logreg_train_acc_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_acc_pred.append(pipe.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe.set_params(**pf1)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    logreg_train_f1_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_f1_pred.append(pipe.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "logreg_train_roc_scores = []\n",
    "logreg_train_acc_scores = []\n",
    "logreg_train_f1_scores = []\n",
    "logreg_test_roc_scores = []\n",
    "logreg_test_acc_scores = []\n",
    "logreg_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    logreg_train_roc_scores.append(roc_auc_score(train_y_sets[i],logreg_train_roc_pred[i]))\n",
    "    logreg_train_acc_scores.append(accuracy_score(train_y_sets[i],logreg_train_acc_pred[i]))\n",
    "    logreg_train_f1_scores.append(f1_score(train_y_sets[i],logreg_train_f1_pred[i]))\n",
    "    logreg_test_roc_scores.append(roc_auc_score(test_y_sets[i],logreg_test_roc_pred[i]))\n",
    "    logreg_test_acc_scores.append(accuracy_score(test_y_sets[i],logreg_test_acc_pred[i]))\n",
    "    logreg_test_f1_scores.append(f1_score(test_y_sets[i],logreg_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "logreg_train_mean_roc = np.mean(logreg_train_roc_scores)\n",
    "logreg_train_mean_acc = np.mean(logreg_train_acc_scores)\n",
    "logreg_train_mean_f1 = np.mean(logreg_train_f1_scores)\n",
    "logreg_test_mean_roc = np.mean(logreg_test_roc_scores)\n",
    "logreg_test_mean_acc = np.mean(logreg_test_acc_scores)\n",
    "logreg_test_mean_f1 = np.mean(logreg_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "logreg_metric_mean_test = np.mean([logreg_test_roc_scores,logreg_test_acc_scores,logreg_test_f1_scores])\n",
    "logreg_metric_mean_train = np.mean([logreg_train_roc_scores,logreg_train_acc_scores,logreg_train_f1_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a random forest object in order to grid search \n",
    "pipe2 =  RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "#setting the possible options for hyperparameters \n",
    "params = [{'n_estimators':[1024],'max_features':[1,2,4,6]}]\n",
    "\n",
    "#creating a gridsearch object \n",
    "clf2 = GridSearchCV(pipe2, params, cv=StratifiedKFold(n_splits=5), scoring=['accuracy', 'roc_auc', 'f1'], refit=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "rf_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    rf_models.append(clf2.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "rf_train_roc_pred = []\n",
    "rf_test_roc_pred = []\n",
    "\n",
    "rf_train_acc_pred = []\n",
    "rf_test_acc_pred = []\n",
    "\n",
    "rf_train_f1_pred = []\n",
    "rf_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe2.set_params(**proc)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    rf_train_roc_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_roc_pred.append(pipe2.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe2.set_params(**pacc)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    rf_train_acc_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_acc_pred.append(pipe2.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe2.set_params(**pf1)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    rf_train_f1_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_f1_pred.append(pipe2.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "rf_train_roc_scores = []\n",
    "rf_train_acc_scores = []\n",
    "rf_train_f1_scores = []\n",
    "rf_test_roc_scores = []\n",
    "rf_test_acc_scores = []\n",
    "rf_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    rf_train_roc_scores.append(roc_auc_score(train_y_sets[i],rf_train_roc_pred[i]))\n",
    "    rf_train_acc_scores.append(accuracy_score(train_y_sets[i],rf_train_acc_pred[i]))\n",
    "    rf_train_f1_scores.append(f1_score(train_y_sets[i],rf_train_f1_pred[i]))\n",
    "    rf_test_roc_scores.append(roc_auc_score(test_y_sets[i],rf_test_roc_pred[i]))\n",
    "    rf_test_acc_scores.append(accuracy_score(test_y_sets[i],rf_test_acc_pred[i]))\n",
    "    rf_test_f1_scores.append(f1_score(test_y_sets[i],rf_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "rf_train_mean_roc = np.mean(rf_train_roc_scores)\n",
    "rf_train_mean_acc = np.mean(rf_train_acc_scores)\n",
    "rf_train_mean_f1 = np.mean(rf_train_f1_scores)\n",
    "rf_test_mean_roc = np.mean(rf_test_roc_scores)\n",
    "rf_test_mean_acc = np.mean(rf_test_acc_scores)\n",
    "rf_test_mean_f1 = np.mean(rf_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "rf_metric_mean_test = np.mean([rf_test_roc_scores,rf_test_acc_scores,rf_test_f1_scores])\n",
    "rf_metric_mean_train = np.mean([rf_train_roc_scores,rf_train_acc_scores,rf_train_f1_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a k Nearest Neighbors object in order to grid search \n",
    "pipe3 =  KNeighborsClassifier()\n",
    "step = 500/26\n",
    "k = np.arange(1,500,step,dtype=int)\n",
    "k_params = [{'n_neighbors':k,'weights':['uniform','distance'],'metric':['euclidean','manhattan']}]\n",
    "\n",
    "clf3 = GridSearchCV(pipe3, k_params, cv=StratifiedKFold(n_splits=5), scoring=['accuracy', 'roc_auc', 'f1'], refit=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "knn_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    knn_models.append(clf3.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "knn_train_roc_pred = []\n",
    "knn_test_roc_pred = []\n",
    "\n",
    "knn_train_acc_pred = []\n",
    "knn_test_acc_pred = []\n",
    "\n",
    "knn_train_f1_pred = []\n",
    "knn_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe3.set_params(**proc)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    knn_train_roc_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_roc_pred.append(pipe3.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe3.set_params(**pacc)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    knn_train_acc_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_acc_pred.append(pipe3.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe3.set_params(**pf1)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    knn_train_f1_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_f1_pred.append(pipe3.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "knn_train_roc_scores = []\n",
    "knn_train_acc_scores = []\n",
    "knn_train_f1_scores = []\n",
    "knn_test_roc_scores = []\n",
    "knn_test_acc_scores = []\n",
    "knn_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    knn_train_roc_scores.append(roc_auc_score(train_y_sets[i],knn_train_roc_pred[i]))\n",
    "    knn_train_acc_scores.append(accuracy_score(train_y_sets[i],knn_train_acc_pred[i]))\n",
    "    knn_train_f1_scores.append(f1_score(train_y_sets[i],knn_train_f1_pred[i]))\n",
    "    knn_test_roc_scores.append(roc_auc_score(test_y_sets[i],knn_test_roc_pred[i]))\n",
    "    knn_test_acc_scores.append(accuracy_score(test_y_sets[i],knn_test_acc_pred[i]))\n",
    "    knn_test_f1_scores.append(f1_score(test_y_sets[i],knn_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "knn_train_mean_roc = np.mean(knn_train_roc_scores)\n",
    "knn_train_mean_acc = np.mean(knn_train_acc_scores)\n",
    "knn_train_mean_f1 = np.mean(knn_train_f1_scores)\n",
    "knn_test_mean_roc = np.mean(knn_test_roc_scores)\n",
    "knn_test_mean_acc = np.mean(knn_test_acc_scores)\n",
    "knn_test_mean_f1 = np.mean(knn_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "knn_metric_mean_test = np.mean([knn_test_roc_scores,knn_test_acc_scores,knn_test_f1_scores])\n",
    "knn_metric_mean_train = np.mean([knn_train_roc_scores,knn_train_acc_scores,knn_train_f1_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.451501</td>\n",
       "      <td>0.106281</td>\n",
       "      <td>0.389609</td>\n",
       "      <td>0.069220</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'max_features': 1, 'n_estimators': 1024}</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.991561</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.894330</td>\n",
       "      <td>0.337298</td>\n",
       "      <td>0.378635</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 1024}</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994742</td>\n",
       "      <td>0.991649</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.990496</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.990968</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.513855</td>\n",
       "      <td>0.505217</td>\n",
       "      <td>0.320225</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 1024}</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.990496</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.246004</td>\n",
       "      <td>0.333807</td>\n",
       "      <td>0.298458</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>6</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 1024}</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.990496</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.990544</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.451501      0.106281         0.389609        0.069220   \n",
       "1       4.894330      0.337298         0.378635        0.065000   \n",
       "2       6.513855      0.505217         0.320225        0.041850   \n",
       "3       8.246004      0.333807         0.298458        0.021756   \n",
       "\n",
       "  param_max_features param_n_estimators  \\\n",
       "0                  1               1024   \n",
       "1                  2               1024   \n",
       "2                  4               1024   \n",
       "3                  6               1024   \n",
       "\n",
       "                                      params  split0_test_accuracy  \\\n",
       "0  {'max_features': 1, 'n_estimators': 1024}                 0.993   \n",
       "1  {'max_features': 2, 'n_estimators': 1024}                 0.995   \n",
       "2  {'max_features': 4, 'n_estimators': 1024}                 0.996   \n",
       "3  {'max_features': 6, 'n_estimators': 1024}                 0.996   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_roc_auc  \\\n",
       "0                 0.994                  0.99  ...          0.000888   \n",
       "1                 0.992                  0.99  ...          0.000779   \n",
       "2                 0.989                  0.99  ...          0.001135   \n",
       "3                 0.989                  0.99  ...          0.000945   \n",
       "\n",
       "   rank_test_roc_auc  split0_test_f1  split1_test_f1  split2_test_f1  \\\n",
       "0                  2        0.992639        0.993724        0.989518   \n",
       "1                  1        0.994742        0.991649        0.989518   \n",
       "2                  3        0.995789        0.988482        0.989518   \n",
       "3                  4        0.995789        0.988482        0.989518   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.991561        0.988433      0.991175     0.001952             1  \n",
       "1        0.990496        0.988433      0.990968     0.002166             2  \n",
       "2        0.990496        0.986301      0.990117     0.003160             4  \n",
       "3        0.990496        0.988433      0.990544     0.002731             3  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_models[2].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(C=630.9573444801918, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=5000, multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                    random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'classifier__C': 630.9573444801918,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_models[1].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_f1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
