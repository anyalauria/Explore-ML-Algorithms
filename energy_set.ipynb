{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algorithms on Electrical Energy Output of Power Plant Dataset\n",
    "* dataset: https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "data = pd.read_excel('datasets/CCP.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the label \n",
    "energy_output = data['PE']\n",
    "\n",
    "#removing label from dataframe\n",
    "data.drop(['PE'], axis=1, inplace=True)\n",
    "\n",
    "#dropping columns with missing rows \n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       0.0\n",
       "2       1.0\n",
       "3       0.0\n",
       "4       1.0\n",
       "       ... \n",
       "9563    1.0\n",
       "9564    1.0\n",
       "9565    0.0\n",
       "9566    0.0\n",
       "9567    0.0\n",
       "Name: PE, Length: 9568, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing data\n",
    "continuous_cols = ['AT','V','AP','RH']\n",
    "features = data[continuous_cols]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "data[continuous_cols] = scaler.transform(features.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.629519</td>\n",
       "      <td>-0.987297</td>\n",
       "      <td>1.820488</td>\n",
       "      <td>-0.009519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741909</td>\n",
       "      <td>0.681045</td>\n",
       "      <td>1.141863</td>\n",
       "      <td>-0.974621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.951297</td>\n",
       "      <td>-1.173018</td>\n",
       "      <td>-0.185078</td>\n",
       "      <td>1.289840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162205</td>\n",
       "      <td>0.237203</td>\n",
       "      <td>-0.508393</td>\n",
       "      <td>0.228160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.185069</td>\n",
       "      <td>-1.322539</td>\n",
       "      <td>-0.678470</td>\n",
       "      <td>1.596699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT         V        AP        RH\n",
       "0 -0.629519 -0.987297  1.820488 -0.009519\n",
       "1  0.741909  0.681045  1.141863 -0.974621\n",
       "2 -1.951297 -1.173018 -0.185078  1.289840\n",
       "3  0.162205  0.237203 -0.508393  0.228160\n",
       "4 -1.185069 -1.322539 -0.678470  1.596699"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mean = np.mean(energy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45829849498327757"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    if (Y[i] >= label_mean):\n",
    "        Y[i] = 1\n",
    "    else:\n",
    "        Y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 5 sets of training and test data \n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y, train_size=5000)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, Y, train_size=5000)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, Y, train_size=5000)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X, Y, train_size=5000)\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X, Y, train_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating arrays of training and test sets \n",
    "train_X_sets = [X1_train,X2_train,X3_train,X4_train,X5_train]\n",
    "test_X_sets = [X1_test,X2_test,X3_test,X4_test,X5_test]\n",
    "\n",
    "#creating arrays of training and test sets \n",
    "train_y_sets = [y1_train,y2_train,y3_train,y4_train,y5_train]\n",
    "test_y_sets = [y1_test,y2_test,y3_test,y4_test,y5_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline in order to grid search \n",
    "pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "# Create search space of candidate learning algorithms and their hyperparameters\n",
    "# note lbfgs can't do l1, and if you pass penalty='none' it expects no C value\n",
    "search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['saga'],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(-8, 4, 11)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs'],\n",
    "                 'classifier__penalty': ['l2'],\n",
    "                 'classifier__C': np.logspace(-8, 4, 11)},\n",
    "                {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                 'classifier__solver': ['lbfgs','saga'],\n",
    "                 'classifier__penalty': ['none']}\n",
    "                ]\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1'], refit=False,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "logreg_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    logreg_models.append(clf.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "logreg_train_roc_pred = []\n",
    "logreg_test_roc_pred = []\n",
    "\n",
    "logreg_train_acc_pred = []\n",
    "logreg_test_acc_pred = []\n",
    "\n",
    "logreg_train_f1_pred = []\n",
    "logreg_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = logreg_models[i].cv_results_['params'][ np.argmin(logreg_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe.set_params(**proc)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    logreg_train_roc_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_roc_pred.append(pipe.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe.set_params(**pacc)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    logreg_train_acc_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_acc_pred.append(pipe.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe.set_params(**pf1)\n",
    "    pipe.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    logreg_train_f1_pred.append(pipe.predict(train_X_sets[i]))\n",
    "    logreg_test_f1_pred.append(pipe.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "logreg_train_roc_scores = []\n",
    "logreg_train_acc_scores = []\n",
    "logreg_train_f1_scores = []\n",
    "logreg_test_roc_scores = []\n",
    "logreg_test_acc_scores = []\n",
    "logreg_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    logreg_train_roc_scores.append(roc_auc_score(train_y_sets[i],logreg_train_roc_pred[i]))\n",
    "    logreg_train_acc_scores.append(accuracy_score(train_y_sets[i],logreg_train_acc_pred[i]))\n",
    "    logreg_train_f1_scores.append(f1_score(train_y_sets[i],logreg_train_f1_pred[i]))\n",
    "    logreg_test_roc_scores.append(roc_auc_score(test_y_sets[i],logreg_test_roc_pred[i]))\n",
    "    logreg_test_acc_scores.append(accuracy_score(test_y_sets[i],logreg_test_acc_pred[i]))\n",
    "    logreg_test_f1_scores.append(f1_score(test_y_sets[i],logreg_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "logreg_train_mean_roc = np.mean(logreg_train_roc_scores)\n",
    "logreg_train_mean_acc = np.mean(logreg_train_acc_scores)\n",
    "logreg_train_mean_f1 = np.mean(logreg_train_f1_scores)\n",
    "logreg_test_mean_roc = np.mean(logreg_test_roc_scores)\n",
    "logreg_test_mean_acc = np.mean(logreg_test_acc_scores)\n",
    "logreg_test_mean_f1 = np.mean(logreg_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "logreg_metric_mean_test = np.mean([logreg_test_roc_scores,logreg_test_acc_scores,logreg_test_f1_scores])\n",
    "logreg_metric_mean_train = np.mean([logreg_train_roc_scores,logreg_train_acc_scores,logreg_train_f1_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a random forest object in order to grid search \n",
    "pipe2 =  RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "#setting the possible options for hyperparameters \n",
    "params = [{'n_estimators':[1024],'max_features':[1,2,4]}]\n",
    "\n",
    "#creating a gridsearch object \n",
    "clf2 = GridSearchCV(pipe2, params, cv=StratifiedKFold(n_splits=5), scoring=['accuracy', 'roc_auc', 'f1'], refit=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "rf_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    rf_models.append(clf2.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "rf_train_roc_pred = []\n",
    "rf_test_roc_pred = []\n",
    "\n",
    "rf_train_acc_pred = []\n",
    "rf_test_acc_pred = []\n",
    "\n",
    "rf_train_f1_pred = []\n",
    "rf_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = rf_models[i].cv_results_['params'][ np.argmin(rf_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe2.set_params(**proc)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    rf_train_roc_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_roc_pred.append(pipe2.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe2.set_params(**pacc)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    rf_train_acc_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_acc_pred.append(pipe2.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe2.set_params(**pf1)\n",
    "    pipe2.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    rf_train_f1_pred.append(pipe2.predict(train_X_sets[i]))\n",
    "    rf_test_f1_pred.append(pipe2.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "rf_train_roc_scores = []\n",
    "rf_train_acc_scores = []\n",
    "rf_train_f1_scores = []\n",
    "rf_test_roc_scores = []\n",
    "rf_test_acc_scores = []\n",
    "rf_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    rf_train_roc_scores.append(roc_auc_score(train_y_sets[i],rf_train_roc_pred[i]))\n",
    "    rf_train_acc_scores.append(accuracy_score(train_y_sets[i],rf_train_acc_pred[i]))\n",
    "    rf_train_f1_scores.append(f1_score(train_y_sets[i],rf_train_f1_pred[i]))\n",
    "    rf_test_roc_scores.append(roc_auc_score(test_y_sets[i],rf_test_roc_pred[i]))\n",
    "    rf_test_acc_scores.append(accuracy_score(test_y_sets[i],rf_test_acc_pred[i]))\n",
    "    rf_test_f1_scores.append(f1_score(test_y_sets[i],rf_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "rf_train_mean_roc = np.mean(rf_train_roc_scores)\n",
    "rf_train_mean_acc = np.mean(rf_train_acc_scores)\n",
    "rf_train_mean_f1 = np.mean(rf_train_f1_scores)\n",
    "rf_test_mean_roc = np.mean(rf_test_roc_scores)\n",
    "rf_test_mean_acc = np.mean(rf_test_acc_scores)\n",
    "rf_test_mean_f1 = np.mean(rf_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "rf_metric_mean_test = np.mean([rf_test_roc_scores,rf_test_acc_scores,rf_test_f1_scores])\n",
    "rf_metric_mean_train = np.mean([rf_train_roc_scores,rf_train_acc_scores,rf_train_f1_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a k Nearest Neighbors object in order to grid search \n",
    "pipe3 =  KNeighborsClassifier()\n",
    "step = 500/26\n",
    "k = np.arange(1,500,step,dtype=int)\n",
    "k_params = [{'n_neighbors':k,'weights':['uniform','distance'],'metric':['euclidean','manhattan']}]\n",
    "\n",
    "clf3 = GridSearchCV(pipe3, k_params, cv=StratifiedKFold(n_splits=5), scoring=['accuracy', 'roc_auc', 'f1'], refit=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models with 5 fold cross validation\n",
    "knn_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    knn_models.append(clf3.fit(train_X_sets[i],train_y_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing array of training and test set predicted values\n",
    "knn_train_roc_pred = []\n",
    "knn_test_roc_pred = []\n",
    "\n",
    "knn_train_acc_pred = []\n",
    "knn_test_acc_pred = []\n",
    "\n",
    "knn_train_f1_pred = []\n",
    "knn_test_f1_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    proc = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_roc_auc'])]\n",
    "    pacc = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_accuracy'])]\n",
    "    pf1 = knn_models[i].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    pipe3.set_params(**proc)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "\n",
    "    knn_train_roc_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_roc_pred.append(pipe3.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe3.set_params(**pacc)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    knn_train_acc_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_acc_pred.append(pipe3.predict(test_X_sets[i]))\n",
    "    \n",
    "    pipe3.set_params(**pf1)\n",
    "    pipe3.fit(train_X_sets[i],train_y_sets[i])\n",
    "    \n",
    "    knn_train_f1_pred.append(pipe3.predict(train_X_sets[i]))\n",
    "    knn_test_f1_pred.append(pipe3.predict(test_X_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing scores arrays for each metric, random forest on adult dataset\n",
    "knn_train_roc_scores = []\n",
    "knn_train_acc_scores = []\n",
    "knn_train_f1_scores = []\n",
    "knn_test_roc_scores = []\n",
    "knn_test_acc_scores = []\n",
    "knn_test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating the scores arrays \n",
    "for i in range(5):\n",
    "    knn_train_roc_scores.append(roc_auc_score(train_y_sets[i],knn_train_roc_pred[i]))\n",
    "    knn_train_acc_scores.append(accuracy_score(train_y_sets[i],knn_train_acc_pred[i]))\n",
    "    knn_train_f1_scores.append(f1_score(train_y_sets[i],knn_train_f1_pred[i]))\n",
    "    knn_test_roc_scores.append(roc_auc_score(test_y_sets[i],knn_test_roc_pred[i]))\n",
    "    knn_test_acc_scores.append(accuracy_score(test_y_sets[i],knn_test_acc_pred[i]))\n",
    "    knn_test_f1_scores.append(f1_score(test_y_sets[i],knn_test_f1_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of each metric across trials\n",
    "knn_train_mean_roc = np.mean(knn_train_roc_scores)\n",
    "knn_train_mean_acc = np.mean(knn_train_acc_scores)\n",
    "knn_train_mean_f1 = np.mean(knn_train_f1_scores)\n",
    "knn_test_mean_roc = np.mean(knn_test_roc_scores)\n",
    "knn_test_mean_acc = np.mean(knn_test_acc_scores)\n",
    "knn_test_mean_f1 = np.mean(knn_test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean across metrics \n",
    "knn_metric_mean_test = np.mean([knn_test_roc_scores,knn_test_acc_scores,knn_test_f1_scores])\n",
    "knn_metric_mean_train = np.mean([knn_train_roc_scores,knn_train_acc_scores,knn_train_f1_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.329298</td>\n",
       "      <td>0.550261</td>\n",
       "      <td>0.345366</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.979667</td>\n",
       "      <td>0.960333</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.970267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.956617</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.969653</td>\n",
       "      <td>0.967574</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.213023</td>\n",
       "      <td>0.633653</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.712373</td>\n",
       "      <td>0.146326</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.969400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967177</td>\n",
       "      <td>0.976898</td>\n",
       "      <td>0.956236</td>\n",
       "      <td>0.962080</td>\n",
       "      <td>0.968581</td>\n",
       "      <td>0.966649</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.068236</td>\n",
       "      <td>0.185107</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.979500</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.967177</td>\n",
       "      <td>0.977460</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.964247</td>\n",
       "      <td>0.969106</td>\n",
       "      <td>0.967278</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.424100</td>\n",
       "      <td>0.223887</td>\n",
       "      <td>0.343704</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.970600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.967177</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.956332</td>\n",
       "      <td>0.966414</td>\n",
       "      <td>0.969631</td>\n",
       "      <td>0.967908</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.137761</td>\n",
       "      <td>0.752228</td>\n",
       "      <td>0.360249</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.971500</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.968770</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.956808</td>\n",
       "      <td>0.967531</td>\n",
       "      <td>0.970189</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.851423</td>\n",
       "      <td>1.280569</td>\n",
       "      <td>0.376794</td>\n",
       "      <td>0.034820</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.970800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.970362</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.957284</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.970748</td>\n",
       "      <td>0.968166</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "count       3.000000      3.000000         3.000000        3.000000   \n",
       "mean        5.329298      0.550261         0.345366        0.020590   \n",
       "std         2.213023      0.633653         0.030631        0.012359   \n",
       "min         3.712373      0.146326         0.315600        0.012530   \n",
       "25%         4.068236      0.185107         0.329652        0.013476   \n",
       "50%         4.424100      0.223887         0.343704        0.014421   \n",
       "75%         6.137761      0.752228         0.360249        0.024620   \n",
       "max         7.851423      1.280569         0.376794        0.034820   \n",
       "\n",
       "       split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  \\\n",
       "count              3.000000              3.000000              3.000000   \n",
       "mean               0.971000              0.979667              0.960333   \n",
       "std                0.001732              0.000577              0.000577   \n",
       "min                0.970000              0.979000              0.960000   \n",
       "25%                0.970000              0.979500              0.960000   \n",
       "50%                0.970000              0.980000              0.960000   \n",
       "75%                0.971500              0.980000              0.960500   \n",
       "max                0.973000              0.980000              0.961000   \n",
       "\n",
       "       split3_test_accuracy  split4_test_accuracy  mean_test_accuracy  ...  \\\n",
       "count              3.000000                3.0000            3.000000  ...   \n",
       "mean               0.968333                0.9720            0.970267  ...   \n",
       "std                0.003055                0.0010            0.000757  ...   \n",
       "min                0.965000                0.9710            0.969400  ...   \n",
       "25%                0.967000                0.9715            0.970000  ...   \n",
       "50%                0.969000                0.9720            0.970600  ...   \n",
       "75%                0.970000                0.9725            0.970700  ...   \n",
       "max                0.971000                0.9730            0.970800  ...   \n",
       "\n",
       "       std_test_roc_auc  rank_test_roc_auc  split0_test_f1  split1_test_f1  \\\n",
       "count          3.000000                3.0        3.000000        3.000000   \n",
       "mean           0.002056                2.0        0.968239        0.977647   \n",
       "std            0.000358                1.0        0.001839        0.000649   \n",
       "min            0.001807                1.0        0.967177        0.976898   \n",
       "25%            0.001851                1.5        0.967177        0.977460   \n",
       "50%            0.001895                2.0        0.967177        0.978022   \n",
       "75%            0.002180                2.5        0.968770        0.978022   \n",
       "max            0.002466                3.0        0.970362        0.978022   \n",
       "\n",
       "       split2_test_f1  split3_test_f1  split4_test_f1  mean_test_f1  \\\n",
       "count        3.000000        3.000000        3.000000      3.000000   \n",
       "mean         0.956617        0.965714        0.969653      0.967574   \n",
       "std          0.000579        0.003340        0.001084      0.000812   \n",
       "min          0.956236        0.962080        0.968581      0.966649   \n",
       "25%          0.956284        0.964247        0.969106      0.967278   \n",
       "50%          0.956332        0.966414        0.969631      0.967908   \n",
       "75%          0.956808        0.967531        0.970189      0.968037   \n",
       "max          0.957284        0.968649        0.970748      0.968166   \n",
       "\n",
       "       std_test_f1  rank_test_f1  \n",
       "count     3.000000           3.0  \n",
       "mean      0.006896           2.0  \n",
       "std       0.000480           1.0  \n",
       "min       0.006362           1.0  \n",
       "25%       0.006698           1.5  \n",
       "50%       0.007033           2.0  \n",
       "75%       0.007162           2.5  \n",
       "max       0.007292           3.0  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_models[0].cv_results_).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 20, 'weights': 'distance'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_models[3].cv_results_['params'][ np.argmin(knn_models[i].cv_results_['rank_test_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,_ = metrics.roc_curve(rf_test_roc_pred[0],test_y_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa6365e46d0>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 253,
       "width": 378
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, b, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
